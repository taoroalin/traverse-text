# Micro Roam

Fast note taking app inspired by Roam Research.

# Features

user settings are stored in seperate from graph, and apply to all graphs that user views. This is theme flags right now, but I'm thinking custom css goes in user local storage as well

# Benchmarks

Site load from my 3Mb graph in local indexedDB: 170ms to 450ms

Page link load: 12ms per page for my 1000 pages. Ranges from 5ms to 200ms for ordinary sized pages, but I've seen 2s for extremely large pages generated by scripts.

Note: Website performance depends on your browser, browser extensions, computer, internet connection, location, phase of the browser GC cycle (basically phase of the moon). The biggest cause of discrepency is browser extensions, which can add 1 second to load times and 50ms to all response times.

# Internals

This project is made with *System Complexity*, in mind. That means instead of writing your own code to be elegant, you write code such that the entire project, including the platform, libraries, frameworks, as a whole is as as simple as possible. Currently the dependencies are:

npm: uglify-js (this has none of its own dependencies. it's very slow, but it actually does everything I need it to)

Backend dependencies: still considering backend options. ScyllaDB, RocksDB look good.

## Data format

All queries, and writes to the store that is queried, happen in the client in the main thread. This is because all writes to memory and queries are fast enough that they are best done synchronously. The data is changed by creating and applying edit objects, which are replicated to a worker thread which spends its time repeatedly serializing store to json (and will be replicated to backend)

Store Data (all the text and stuff the user creates) is stored indexedDB in a single JSON string. This improves the read and write speed compared to having indexedDB do the serialization (without any indexes). The JSON contains 3 flat maps: blocks, pages, pagesById:

blockId:{string,create-time,edit-time,refs,:block/refs, backRefs,parentId}

pageId:{string,create-time,edit-time,refs,:block/refs, backRefs}

pageTitle:pageId

User settings type data is stored in seperate object in localStorage

Session specific data, for the recording browser history, in sessionState. The current state is global and updated mutably, then copied into a seperate object when needed to remember states.

Querying pageTitles for titles would take around 1ms, so it's unclear whether pagesById is necessary, but I think it is. backRefs is more obviously needed. Refs are stored in arrays, not Set, object, or whatever because JSON serialization is important and a Set would actually be slower for everything.

There are a large number of global variables, all (mutable ones) declared in startup.js. They include active cursor/block information, which are all set at once by updateCursorInfo, which are read by many event handlers

## Code organization

The code is arranged by when it is run, not what part of the system it's in. All the event handlers are together, renderers are together, queries are together, commands are together, ect, instead of being arranged into components which each have their own event handling, logic, ect. 

All event handling for non-permanent elements (anything without id) is done through global documend event handlers which switch on the target element. I did this because I thought it would speed up rendering (when you click a link, event handler runs once, but block renderer runs 100 times, so move code from renderer to event handler). Still might move towards a more normal structure.


## Templating

I'm using HTML `<template>`s, `cloneNode`, and `element.firstElementChild.children[1].innerText=` for templating because it's the most performant out of methids I tested (more so than string replacement or `document.createElement`). This is hard to read and overly coupled, so I may make an abstraction over this. The highest performance option (which would not be tremendously more performant than other options) is a preprocessor that reads positions of classes within templates and replaces "calls" to those classes with `element.firstElementChild.children[1]` type stuff. Query at compile time, not runtime.

## Future improvements

Handling huge block parses. Right now it works well up to something like 500 syntax elements per block. Gets synchronously laggy after that.

Store chached stuff (pagesByTitle, backRefs, refs, :block/refs), seperately. Then the core data has far less room for corruption. Store save id for core data and cache, then you can fast forward cache too. In the beginning, don't even save cache data to backend at all. This means edits are reasonable sized! this is a major data refactor.

Make each page render (and block render?) keep track of how long it's taken and break + resume when it takes too long

Maybe make bracket auto close not happen when you're right in front of word??

When there is cross-graph linking, load graphs when they're needed before first render, then do others in 50ms chunks

# Working on right now

Seperating core state (strings & child structure) from backrefs / pagesFromTitle

Using query params to specify page / block in site

Storing edits / commits with uuids